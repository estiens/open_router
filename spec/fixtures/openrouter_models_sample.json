{
  "data": [
    {
    "id": "mistralai/mistral-medium-3.1",
    "canonical_slug": "mistralai/mistral-medium-3.1",
    "hugging_face_id": "",
    "name": "Mistral: Mistral Medium 3.1",
    "created": 1755095639,
    "description": "Mistral Medium 3.1 is an updated version of Mistral Medium 3, which is a high-performance enterprise-grade language model designed to deliver frontier-level capabilities at significantly reduced operational cost. It balances state-of-the-art reasoning and multimodal performance with 8Ã— lower cost compared to traditional large models, making it suitable for scalable deployments across professional and industrial use cases.\n\nThe model excels in domains such as coding, STEM reasoning, and enterprise adaptation. It supports hybrid, on-prem, and in-VPC deployments and is optimized for integration into custom workflows. Mistral Medium 3.1 offers competitive accuracy relative to larger models like Claude Sonnet 3.5/3.7, Llama 4 Maverick, and Command R+, while maintaining broad compatibility across cloud environments.",
    "context_length": 262144,
    "architecture": {
      "modality": "text+image->text",
      "input_modalities": [
        "text",
        "image"
      ],
      "output_modalities": [
        "text"
      ],
      "tokenizer": "Mistral",
      "instruct_type": null
    },
    "pricing": {
      "prompt": "0.0000004",
      "completion": "0.000002",
      "request": "0",
      "image": "0",
      "audio": "0",
      "web_search": "0",
      "internal_reasoning": "0"
    },
    "top_provider": {
      "context_length": 262144,
      "max_completion_tokens": null,
      "is_moderated": false
    },
    "per_request_limits": null,
    "supported_parameters": [
      "frequency_penalty",
      "max_tokens",
      "presence_penalty",
      "response_format",
      "seed",
      "stop",
      "structured_outputs",
      "temperature",
      "tool_choice",
      "tools",
      "top_p"
    ]
  },
  {
    "id": "z-ai/glm-4.5v",
    "canonical_slug": "z-ai/glm-4.5v",
    "hugging_face_id": "zai-org/GLM-4.5V",
    "name": "Z.AI: GLM 4.5V",
    "created": 1754922288,
    "description": "GLM-4.5V is a vision-language foundation model for multimodal agent applications. Built on a Mixture-of-Experts (MoE) architecture with 106B parameters and 12B activated parameters, it achieves state-of-the-art results in video understanding, image Q&A, OCR, and document parsing, with strong gains in front-end web coding, grounding, and spatial reasoning. It offers a hybrid inference mode: a \"thinking mode\" for deep reasoning and a \"non-thinking mode\" for fast responses. Reasoning behavior can be toggled via the `reasoning` `enabled` boolean. [Learn more in our docs](https://openrouter.ai/docs/use-cases/reasoning-tokens#enable-reasoning-with-default-config)",
    "context_length": 65536,
    "architecture": {
      "modality": "text+image->text",
      "input_modalities": [
        "text",
        "image"
      ],
      "output_modalities": [
        "text"
      ],
      "tokenizer": "Other",
      "instruct_type": null
    },
    "pricing": {
      "prompt": "0.0000005",
      "completion": "0.0000017",
      "request": "0",
      "image": "0",
      "audio": "0",
      "web_search": "0",
      "internal_reasoning": "0"
    },
    "top_provider": {
      "context_length": 65536,
      "max_completion_tokens": 65536,
      "is_moderated": false
    },
    "per_request_limits": null,
    "supported_parameters": [
      "frequency_penalty",
      "include_reasoning",
      "logit_bias",
      "max_tokens",
      "min_p",
      "presence_penalty",
      "reasoning",
      "repetition_penalty",
      "response_format",
      "seed",
      "stop",
      "temperature",
      "tool_choice",
      "tools",
      "top_k",
      "top_p"
    ]
  },
  {
    "id": "ai21/jamba-mini-1.7",
    "canonical_slug": "ai21/jamba-mini-1.7",
    "hugging_face_id": "ai21labs/AI21-Jamba-Mini-1.7",
    "name": "AI21: Jamba Mini 1.7",
    "created": 1754670601,
    "description": "Jamba Mini 1.7 is a compact and efficient member of the Jamba open model family, incorporating key improvements in grounding and instruction-following while maintaining the benefits of the SSM-Transformer hybrid architecture and 256K context window. Despite its compact size, it delivers accurate, contextually grounded responses and improved steerability.",
    "context_length": 256000,
    "architecture": {
      "modality": "text->text",
      "input_modalities": [
        "text"
      ],
      "output_modalities": [
        "text"
      ],
      "tokenizer": "Other",
      "instruct_type": null
    },
    "pricing": {
      "prompt": "0.0000002",
      "completion": "0.0000004",
      "request": "0",
      "image": "0",
      "audio": "0",
      "web_search": "0",
      "internal_reasoning": "0"
    },
    "top_provider": {
      "context_length": 256000,
      "max_completion_tokens": 4096,
      "is_moderated": false
    },
    "per_request_limits": null,
    "supported_parameters": [
      "max_tokens",
      "response_format",
      "stop",
      "temperature",
      "tool_choice",
      "tools",
      "top_p"
    ]
  },
  {
    "id": "ai21/jamba-large-1.7",
    "canonical_slug": "ai21/jamba-large-1.7",
    "hugging_face_id": "ai21labs/AI21-Jamba-Large-1.7",
    "name": "AI21: Jamba Large 1.7",
    "created": 1754669020,
    "description": "Jamba Large 1.7 is the latest model in the Jamba open family, offering improvements in grounding, instruction-following, and overall efficiency. Built on a hybrid SSM-Transformer architecture with a 256K context window, it delivers more accurate, contextually grounded responses and better steerability than previous versions.",
    "context_length": 256000,
    "architecture": {
      "modality": "text->text",
      "input_modalities": [
        "text"
      ],
      "output_modalities": [
        "text"
      ],
      "tokenizer": "Other",
      "instruct_type": null
    },
    "pricing": {
      "prompt": "0.000002",
      "completion": "0.000008",
      "request": "0",
      "image": "0",
      "audio": "0",
      "web_search": "0",
      "internal_reasoning": "0"
    },
    "top_provider": {
      "context_length": 256000,
      "max_completion_tokens": 4096,
      "is_moderated": false
    },
    "per_request_limits": null,
    "supported_parameters": [
      "max_tokens",
      "response_format",
      "stop",
      "temperature",
      "tool_choice",
      "tools",
      "top_p"
    ]
  },
  {
    "id": "openai/gpt-5-chat",
    "canonical_slug": "openai/gpt-5-chat-2025-08-07",
    "hugging_face_id": "",
    "name": "OpenAI: GPT-5 Chat",
    "created": 1754587837,
    "description": "GPT-5 Chat is designed for advanced, natural, multimodal, and context-aware conversations for enterprise applications.",
    "context_length": 400000,
    "architecture": {
      "modality": "text+image->text",
      "input_modalities": [
        "file",
        "image",
        "text"
      ],
      "output_modalities": [
        "text"
      ],
      "tokenizer": "GPT",
      "instruct_type": null
    },
    "pricing": {
      "prompt": "0.00000125",
      "completion": "0.00001",
      "request": "0",
      "image": "0",
      "audio": "0",
      "web_search": "0",
      "internal_reasoning": "0",
      "input_cache_read": "0.000000125"
    },
    "top_provider": {
      "context_length": 400000,
      "max_completion_tokens": 128000,
      "is_moderated": true
    },
    "per_request_limits": null,
    "supported_parameters": [
      "include_reasoning",
      "max_tokens",
      "reasoning",
      "response_format",
      "seed",
      "structured_outputs"
    ]
  }
  ]
}
